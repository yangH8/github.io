<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Xuyang Bai</title>
  
  <meta name="author" content="Huitong Yang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:850px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Huitong Yang 杨蕙同</name>
              </p>
              <p>I received the M.S. degree in optical engineering from Guangdong University of Technology, China, in 2022. I am working closely with <a href="https://sist.shanghaitech.edu.cn/2020/0914/c7499a55628/page.htm"> Prof. Yuexin Ma</a> at 4DVLab in ShanghaiTech University and <a href="https://hangzhaomit.github.io/"> Prof. Hang Zhao</a> at <a href="http://group.iiis.tsinghua.edu.cn/~marslab/"> MARS Lab</a> in Shang Hai Qi Zhi Institute.</p>
              <p style="text-align:center">
                <a href="mailto:huitongy0126@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/cv_tex__Copy_.pdf">CV</a> &nbsp/&nbsp
                <a href="https://github.com/yangH8">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/XuyangBAI.jpg"><img style="width:70%;max-width:100%" alt="profile photo" src="images/XuyangBAI.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
              <tr>
                  <td style="padding:20px;width:100%;vertical-align:middle">
                    <p style="font-size: 18px;">
                      2023.01: <span style="color: red;font-weight: 700;">NEW!!</span> One Training for Multiple Deployments: Polar-based Adaptive BEV Perception for Autonomous Driving is accepted by ICRA2023.
                    </p>
                    <p style="font-size: 18px;">
                    2022.08: <span style="color: red;font-weight: 700;">NEW!!</span> <a href="https://arxiv.org/pdf/2208.02797" style="font-size: 18px;">Vision-Centric BEV Perception: A Survey</a> is released and project page at <a href="https://github.com/4DVLab/Vision-Centric-BEV-Perception" style="font-size: 18px;">this URL</a>.
                    </p>
                  </td>
              </tr>
          </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I am interested in 3D perception for autonomous vehicles(3D Detection, point cloud segmentation) and scene understanding(stereo matching).
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px ;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/VMNet_TPAMI2022.png" alt="VMNet_TPAMI2022" width="200" height="" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/pdf/2208.02797">
                <papertitle>Vision-Centric BEV Perception: A Survey</papertitle>
              </a>
              <br>
              Yuexin Ma, Tai Wang, Xuyang Bai,  <strong>Huitong Yang</strong>, Yuenan Hou, Yaming Wang, Yu Qiao, Ruigang Yang, Dinesh Manocha, Xinge Zhu
              <br>
              <em>TPAMI</em>, 2023(Submitted)
              <br>
              <a href="https://arxiv.org/pdf/2208.02797">paper</a>  / 
              <a href="https://github.com/4DVLab/Vision-Centric-BEV-Perception">code</a>  / 
              bibtex
              <!-- <p>A computational efficient image feature matching model which adopts a graph neural network with sparse structure to reduce redundant connectivity and learn compact representation. </p> -->
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/LiDAL_ECCV2022.png" alt="LiDAL_ECCV2022" width="200" height="" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
             
                <papertitle>One Training for Multiple Deployments: Polar-based Adaptive BEV Perception for Autonomous Driving</papertitle>
             
              <br>
               <strong>Huitong Yang</strong>,  Xuyang Bai, Xinge Zhu, and Yuexin Ma
              <br>
              <em>ICRA</em>, 2023(Accepted)
              <br>
              paper / 
              code / 
              bibtex
              <!-- <p>A computational efficient image feature matching model which adopts a graph neural network with sparse structure to reduce redundant connectivity and learn compact representation. </p> -->
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/TransFusion_CVPR2022.png" alt="SGMNet" width="200" height="" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              
                <papertitle>GAMNet: Global Attention Via Multi-scale Context
for Depth Measurement Algorithm and Application.</papertitle>
              
              <br> <strong>Huitong Yang</strong>,   Qi Wang, Liang Lei
              <br>Measurement Science and Technology(MST), 2023(Submitted)
              <br>
            
              paper / 
              code/ 
              bibtex
              <!-- <p>A computational efficient image feature matching model which adopts a graph neural network with sparse structure to reduce redundant connectivity and learn compact representation. </p> -->
            </td>
          </tr>


          


        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
              <tr>
                  <td style="padding:20px;width:100%;vertical-align:middle">
                      <heading>Experience</heading>
                      <p></p>
                      <li>ShanghaiTech University, Mar. 2022 - Dec. 2022</li>
                      <li>Shanghai Qi Zhi Institute, Jan. 2023 - Now </li>
                  </td>
              </tr>
          </tbody>
      </table>



      </td>
    </tr>
  </table>
</body>

</html>
